---
title: "Building Deep Learning Models"
author: ' Xiaoyong Pan, Jenna Reps, Peter R. Rijnbeek,'
date: '`r Sys.Date()`'
header-includes:
    - \usepackage{fancyhdr}
    - \pagestyle{fancy}
    - \fancyhead{}
    - \fancyhead[CO,CE]{Building Deep Learning Models}
    - \fancyfoot[CO,CE]{PatientLevelPrediction Package Version `r    utils::packageVersion("PatientLevelPrediction")`}
    - \fancyfoot[LE,RO]{\thepage}
    - \renewcommand{\headrulewidth}{0.4pt}
    - \renewcommand{\footrulewidth}{0.4pt}
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Electronic Health Records data is high dimensional, heterogeneous, and sparse, which makes predictive modelling a challenge. In the early days, the machine learning community mainly focused on algorithm development, currently there is a shift to more powerful feature engineering. Deep learning models are widely used to automatically learn high-level feature representations from the data, and have achieved remarkable results in image processing,  speech recognition and computational biology. Recently, interesting results have been shown in healthcare applications using EHR data.

This vignette describes how you can use the Observational Health Data Sciences and Informatics (OHDSI) [`PatientLevelPrediction`](http://github.com/OHDSI/PatientLevelPrediction) package to build deep learning models. This vignette assumes you have read and are comfortable with building patient level prediction models as described in the  [`BuildingPredictiveModels` vignette](https://github.com/OHDSI/PatientLevelPrediction/blob/master/inst/doc/BuildingPredictiveModels.pdf). Furthermore, this vignette assumes you are familiar with Deep Learning methods.

# Background

Deep learning models are build by stacking often a large number of neural network layers that perform feature engineering steps, e.g embedding, and are collapsed in a final softmax layer (basically a logistic regression layer). These algorithms need a lot of data to converge to a good representation, but currently the sizes of the EHR databases are growing fast which would make Deep Learning an interesting approach to test within the OHDSI Patient-Level Prediction Framework. For relatively small Target and Outcome cohorts, Deep Learning is most probaby not the best choice.

Multiple Deep Learning backends have been developed, e.g. Tensorflow, PyTorch, Keras etc. In the package we have implemented interaction with Keras and PyTorch but we invite the community to add other backends. 

Many network topologies have recently been proposed and we have implemented a number of them, however, this list will grow in the near future. It is important to understand that some of these topologies require a 2D data matrix, i.e. |patient|x|feature|, and others use a 3D data matrix |patient|x|feature|X|time|. The FeatureExtraction Package has been extended to enable the extraction of both data formats as will be described with examples below.

Training Deep Learning Models is computationally intensive, our implementation therefore supports both GPU and CPU. It will automatically check whether there is GPU or not in your computer. A GPU is highly recommended for Deep Learning!

# Non-Temporal topologies
We implement the following non-temporal (2D data matrix) topologies using Pytorch:

	1) Logistics regression (LRTorch)
	   A simple softmax layer with l2 regularisation
	
	2) Feedforward network (MLPTorch) 
	   Supports multilayer perceptron (mlp_type = MLP) and 
	   Self-Normalizing Neural Networks (mlp_type = SNN)
	   Reference: https://arxiv.org/abs/1706.02515

For the above two methods, we implemented support for a stacked autoencoder and a variational autoencoder to reduce the feature dimension as a first step. These autoencoders learn efficient data codings in an unsupervised manner by stacking multiple layers in a neural network. 

Table 1: Non-Temporal Deep Learning Models Hyper-Parameters

Name | Description | Hyperparameters
-------- | --------------------------- | ------------------------------------- 
LRTorch | Logistic Regression Model | w_decay (l2 regularisation), epochs (number of epochs), class_weight (0 = inverse ratio between number of positive and negative examples, -1 = focal loss (https://arxiv.org/abs/1708.02002), or other), autoencoder (apply stacked autoencoder?, vae (apply variational autoencoder)
MLPTorch | Multi-Layer Perceptron Model | mlp_type (MLP = default, SNN = self-normalizing neural network), size (number of hidden nodes), w_decay (l2 regularisation), epochs (number of epochs), class_weight(0 = inverse ratio between number of positive and negative examples, -1 = focal loss, or other), autoencoder (apply stacked autoencoder), vae (apply variational autoencoder?)

##Example
The approach for logistic regression (LRTorch) and the Multi-Layer Perceptron (MLPTorch) is identical. Here we will take LRTorch as an example.

You need to generate a `population` and `plpData` object as described in more detail in [`BuildingPredictiveModels` vignette](https://github.com/OHDSI/PatientLevelPrediction/blob/master/inst/doc/BuildingPredictiveModels.pdf). 

Alternatively, you can make use of the data simulator. The following code snippet creates a population of 12000 patients.

```{r eval=FALSE}
set.seed(1234)
data(plpDataSimulationProfile)
sampleSize <- 12000
plpData <- simulatePlpData(
  plpDataSimulationProfile,
  n = sampleSize
)

population <- createStudyPopulation(
  plpData,
  outcomeId = 2,
  binary = TRUE,
  firstExposureOnly = FALSE,
  washoutPeriod = 0,
  removeSubjectsWithPriorOutcome = FALSE,
  priorOutcomeLookback = 99999,
  requireTimeAtRisk = FALSE,
  minTimeAtRisk = 0,
  riskWindowStart = 0,
  addExposureDaysToStart = FALSE,
  riskWindowEnd = 365,
  addExposureDaysToEnd = FALSE,
  verbosity = futile.logger::INFO
)
```

Specify the prediction algorithm you like to develop.

```{r eval=FALSE}
# Use Logistics regression
model <- setLRTorch()
```

Additionally, we can specify the stacked autoencoder to be used for reducing the feature dimension as an initial layer.

```{r}
# Use stacked autoencoder.
autoencoder <- FALSE
```

Alternatively, a variational autoencoder could be used for reducing the feature dimension.

```{r}
# Use variational autoencoder.
vae <- FALSE
```
NEED TO CHANGE THE PARAMETER TO LEVEL.

Specify a class_weight for imbalanced data, the default value is the inverse ratio between negatives and positives. 

```{r eval = FALSE}
class_weight <- 2

```

```{r eval=FALSE}
# Use Logistics regression
model <- setLRTorch(autoencoder=autoencoder, vae=vae,  class_weight=class_weight)
```

Specify a test fraction.

```{r eval = FALSE}
testFraction <- 0.2

```

Specify the test split to be used.

```{r}
# Use a split by person, alternatively a time split is possible
testSplit <- 'person'
```


Run the model training.

```{r eval=FALSE}
results <- PatientLevelPrediction::runPlp(population, plpData, 
                                                    model,
                                                    testSplit=testSplit,
                                                    testFraction=testFraction,
                                                    nfold=3, splitSeed=1000) 
```

# Temporal Architectures
Several topologies are implemented that can handle temporal data in pyTorch and R Keras.

## PyTorch CNN

We implemented the following **convolutional** models described in https://github.com/clinicalml/deepDiagnosis in CNNTorch:

1) <dl>
    <dt>Temporal Convolutional neural network over a backward window (type = cnn)</dt>
    <dd>![](arch1.png)</dd>
  </dl>
  
2) <dl>
    <dt>Convolutional neural network over input and time dimension (type = mix)</dt>
    <dd>![](conv_arch2.png)</dd>
  </dl>

3) <dl>
    <dt>Multi-resolution temporal convolutional neural network  (type = multi)</dt>
    <dd>![](conv_arch1.png)</dd>
  </dl>
  
Furthermore, we added the following topologies:

4) <dl>
    <dt>CNN with filters with three different parallel kernel sizes (3,4,5) and a fully connected layers (type = mlf)</dt>
    <dd>![](cnn_mlf2.png)</dd>
  </dl>
  
5) <dt>LSTM network over the backward window  (type = lstm) </dt>
    <dd>![](cnn_lstm.png)</dd>
  </dl> 
  
6) <dt>Residual Learning Network as descripted in: https://arxiv.org/abs/1512.03385 (type = resnet) </dt>
    <dd>This a very big network, see the paper for the topology.</dd>
   </dl> 

parameter | description
---------- | --------------------------
nbfilters | The number of convolution filters
epochs    | The number of epochs
seed      | Random seed 
class_weight  | The class weight used for imbalanced data <br> (0: Inverse ratio between positives and negatives, -1: Focal loss, or number)

## PyTorch RNN
The following **recurrent neural network** models are implemented in RNNTorch:

1) <dl>
    <dt>RNN with one LSTM layer fed into one fully connected layer (type = RNN)</dt>
    <dd><dd>![](lstm_last.png)</dd></dd>
  </dl>

2) <dl>
    <dt>RNN with one bidirectional LSTM layer fed into one fully connected layer (type = BiRNN)</dt>
    <dd>This network looks the same as above but then as a bi-directional version</dd>
  </dl>
  
3) <dl>
    <dt>One Gated Recurrent Unit layer fed into one fully connected layers (type = GRU)</dt>
    <dd>This network looks the same as above but then implemented as GRU</dd>
  </dl>
  
The following hyper-parameters can be set for these pyTorch models:

parameter | description
---------- | --------------------------
hidden_size | The number of features in hidden state
epochs    | The number of epochs
seed      | Random seed 
class_weight  | The class weight used for imbalanced data <br> (0: Inverse ratio between positives and negatives, -1: Focal loss, or number)

## R Keras CNN	
The following temporal architectures were implemented using R Keras:

  1. <dl>
       <dt>Multi-resolution CovNN model according to https://arxiv.org/pdf/1608.00647.pdf (CovNN.R)</dt>
       <dd>![](covcnn.png)</dd>
     </dl>
  
  2. <dl>
       <dt>Convolution accross data and time according to https://arxiv.org/pdf/1608.00647.pdf (CovNN2.R)</dt>
       <dd>![](covcnn2.png)</dd>
     </dl>

  3. <dl>
       <dt>Clinically Informing application based on Recurrent Neural Network (CIReNN)</dt>
       <dd>Image to be added.</dd>
     </dl>
  
Table 2: Temporal Deep Learning Models

Model |  Hyperparameters
--------- |  --------------------------------------------------------------------
CovNN | batchSize (The number of samples to used in each batch during model training), outcomeWeight (The weight assigned to the outcome), lr (The learning rate), decay (The decay of the learning rate), dropout ([currently not used] the dropout rate for regularisation), epochs (The number of times data is used to train the model, e.g., epoches=1 means data only used once to train), filters (The number of columns output by each convolution), kernelSize (The number of time dimensions used for each convolution), loss (The loss function implemented), seed (The random seed)
CovNN2 | batchSize (The number of samples to used in each batch during model training), outcomeWeight (The weight assigned to the outcome), lr (The learning rate), decay (The decay of the learning rate), dropout ([currently not used] the dropout rate for regularisation), epochs (The number of times data is used to train the model, e.g., epoches=1 means data only used once to train), filters (The number of columns output by each convolution), kernelSize (The number of time dimensions used for each convolution), loss (The loss function implemented), seed (The random seed)
CIReNN | units (The number of units of RNN layer - as a list of vectors), recurrentDropout (The reccurrent dropout rate), layerDropout (The layer dropout rate), lr (Learning rate), decay (Learning rate decay over each update), outcomeWeight (The weight of the outcome class in the loss function), batchSize (The number of data points to use per training batch), epochs (Number of times to iterate over dataset), earlyStoppingMinDelta (Minimum change in the monitored quantity to qualify as an improvement for early stopping, i.e. an absolute change of less than min_delta in loss of validation data, will count as no improvement), earlyStoppingPatience (Number of epochs with no improvement after which training will be stopped), seed (Random seed used by deep learning model)
  

## Example
We will now show how to use the temporal models by usinng CNNTorch as an example.

You need to generate a `population` and `plpData` object as described in more detail in [`BuildingPredictiveModels` vignette](https://github.com/OHDSI/PatientLevelPrediction/blob/master/inst/doc/BuildingPredictiveModels.pdf). 

Note that for these algorithms you need to extracted temporal data as described in the [FeatureExtraction vignette] (https://github.com/OHDSI/FeatureExtraction/blob/master/inst/doc/UsingFeatureExtraction.pdf) as follows:

```{r eval=FALSE}
settings <- createTemporalCovariateSettings(useConditionEraStart = FALSE,
                                            useConditionEraOverlap = FALSE,
                                            useConditionOccurrence = FALSE,
                                            useConditionEraGroupStart = FALSE,
                                            useConditionEraGroupOverlap = FALSE,
                                            useDrugExposure = FALSE,
                                            useDrugEraStart = FALSE,
                                            useDrugEraOverlap = FALSE,
                                            useMeasurement = FALSE,
                                            useMeasurementValue = TRUE,
                                            useMeasurementRangeGroup = FALSE,
                                            useProcedureOccurrence = FALSE,
                                            useDeviceExposure = FALSE,
                                            useObservation = FALSE,
                                            excludedCovariateConceptIds = c(316866),
                                            addDescendantsToExclude = TRUE,
                                            temporalStartDays = seq(from = -365, 
                                                                    to = -1, by = 12), 
                                            temporalEndDays = c(seq(from = -353, 
                                                                    to = 0, by = 12), 0))

plpData <- getPlpData(connectionDetails = connectionDetails,
                        cdmDatabaseSchema = cdmDatabaseSchema,
                        cohortDatabaseSchema = "results",
                        cohortTable = "cohort",
                        cohortId = 11,
                        covariateSettings = settings,
                        outcomeDatabaseSchema = resultsDatabaseSchema,
                        outcomeTable = "cohort",
                        outcomeIds = 25,
                        cdmVersion = 5)

```

Each CNN/RNN has several hyper-parameters that can be set as shown in the Tables above, but for this example we take the defaults. 

```{r eval=FALSE}
# specify the the CNN
model <- setCNNTorch(cnn_type='CNN')
```

Run the model training, for example with a testFraction = 0.2 and a split by person:

```{r eval=FALSE}
results <- PatientLevelPrediction::runPlp(population, plpData, model,
                                          testSplit='person',
                                          testFraction=0.2,
                                          nfold=3, 
                                          splitSeed=1000) 
```

# Apply the trained Deep Learning model
Applying a Deep Learning is identical to the other models in the package:

```{r eval=FALSE}
# load the trained model
plpModel <- loadPlpModel(getwd(), "\<model\>")

# load the new plpData (should have the same temporal features!) and create the population
plpData <- loadPlpData(getwd(), "\<data\>")

populationSettings <- plpModel$populationSettings
populationSettings$plpData <- plpData
population <- do.call(createStudyPopulation, populationSettings)  

# apply the trained model on the new data
validationResults <- applyModel(population, plpData, plpModel)
```

# Adding new architectures

If you like to add new architectures you have the option to add them using pyTorch of R Keras.

## pyTorch
XIAOYONG is working on some text for this.

## R Keras
JENNA:  Add some details

# Acknowledgments

Considerable work has been dedicated to provide the `PatientLevelPrediction` package.

```{r tidy=TRUE,eval=TRUE}
citation("PatientLevelPrediction")
```

**Please reference this paper if you use the PLP Package in your work:**

[Reps JM, Schuemie MJ, Suchard MA, Ryan PB, Rijnbeek PR. Design and implementation of a standardized framework to generate and evaluate patient-level prediction models using observational healthcare data. J Am Med Inform Assoc. 2018;25(8):969-975.](http://dx.doi.org/10.1093/jamia/ocy032)